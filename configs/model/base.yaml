d_model: 512
num_encoder_layers: 6
num_decoder_layers: 6
num_attention_heads: 8
ffn_dim: 2048
dropout: 0.1
