# Small config for quick testing (no pretrained weights)
d_model: 512
num_encoder_layers: 6
num_decoder_layers: 6
num_attention_heads: 8
ffn_dim: 1024
dropout: 0.1
activation: gated-gelu  # Use gated-gelu for T5 compatibility
use_pretrained: false
pretrained_model_name: google/flan-t5-small
