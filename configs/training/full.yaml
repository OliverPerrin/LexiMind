# Full Training Configuration for FLAN-T5-base
# BEST QUALITY - use for final model training
# VRAM Usage: ~9-10GB (12GB available)
# Training time: ~1 hour on RTX 4070 12GB
# Use: python scripts/train.py training=full

dataloader:
  batch_size: 10  # Optimal for RTX 4070 12GB
  shuffle: true
  num_workers: 4
  pin_memory: true
  persistent_workers: true
  prefetch_factor: 2

optimizer:
  name: adamw
  lr: 1.5e-5  # Lower LR for best convergence
  weight_decay: 0.02  # Increased regularization
  eps: 1.0e-6
  betas: [0.9, 0.98]  # Lower beta2 for faster adaptation

scheduler:
  name: cosine
  warmup_steps: 800  # Longer warmup for larger dataset

trainer:
  max_epochs: 6  # Reduced - converges by epoch 4-5
  gradient_clip_norm: 1.0
  gradient_accumulation_steps: 8  # Larger effective batch: 80 (10*8)
  validation_max_length: 128
  label_smoothing: 0.15  # Increased for better generalization
  task_weights:
    summarization: 1.0
    emotion: 2.0  # Boost emotion more (tends to underfit)
    topic: 0.3  # Reduced more - topic saturates quickly
  max_train_samples: 50000
  max_val_samples: 3000
  early_stopping_patience: 2  # Stop earlier on plateau
  log_grad_norm_frequency: 100

compile_encoder: true
compile_decoder: true

# FULL QUALITY SETTINGS
tokenizer_max_length: 512  # Full context for summarization
gradient_checkpointing: true

# FLAN-T5 has NO learned positional embeddings - only relative position bias
# Disabling this causes repetition loops (model can't track sequence position)
use_relative_position_bias: true

# Freeze lower encoder layers (0-5) to preserve pretrained knowledge
# Upper layers (6-11) adapt to summarization style
freeze_encoder_layers: 6
