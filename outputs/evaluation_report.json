{
  "summarization": {
    "rouge1": 0.30642430379446967,
    "rouge2": 0.08959565281855562,
    "rougeL": 0.18324654816276506,
    "bleu4": 0.02372948091924369,
    "num_samples": 2727,
    "bertscore_precision": 0.8429681658744812,
    "bertscore_recall": 0.817944347858429,
    "bertscore_f1": 0.8300431966781616
  },
  "emotion": {
    "multilabel_f1": 0.19874678552150726,
    "sample_avg_f1": 0.19874677478805736,
    "num_samples": 5426,
    "num_classes": 28
  },
  "topic": {
    "accuracy": 0.8518518518518519,
    "macro_f1": 0.8473591074094903,
    "num_samples": 189
  }
}